{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e48379c1-d300-4f0f-aefc-bd504c3ae1f8",
      "metadata": {
        "id": "e48379c1-d300-4f0f-aefc-bd504c3ae1f8"
      },
      "source": [
        "### **Sentiment Analysis** ###"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e878c928-9484-4dd1-a58b-97e5abd570b9",
      "metadata": {
        "id": "e878c928-9484-4dd1-a58b-97e5abd570b9"
      },
      "source": [
        "El Análisis de Sentimiento tiene como objetivo determinar y clasificar la polaridad emocional de un fragmento de texto. La polaridad emocional puede ser positiva, negativa o neutra, y el objetivo del análisis de sentimiento es comprender la actitud, opinión o emoción expresada en el texto.\n",
        "\n",
        "Vamos a trabajar en un [ejemplo](https://www.tensorflow.org/text/tutorials/text_classification_rnn) que permita clasificar comentarios sobre películas como positivo, negativo o neutro."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc6cb4a8-a139-46dc-8b20-e4a28bdff90c",
      "metadata": {
        "id": "bc6cb4a8-a139-46dc-8b20-e4a28bdff90c"
      },
      "source": [
        "**Módulos:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e4eb50c-a5e5-4224-8c30-81f413ace1c0",
      "metadata": {
        "id": "3e4eb50c-a5e5-4224-8c30-81f413ace1c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e528a2f-98be-47f4-8470-b05203268a39",
      "metadata": {
        "id": "9e528a2f-98be-47f4-8470-b05203268a39"
      },
      "source": [
        "**Dataset:**\n",
        "\n",
        "Vamos a trabajar con el Dataset de Comentarios de Películas IMDB de Keras. Contiene 25.000 comentarios, cada uno de ellos preprocesados y clasificados como Positivo o Negativo. Cada comentarios está codificado con enteros que representan la frecuencia de una palabra en el Dataset completo. Por ejemplo, una palabra codificada con el entero 3 significa que es la tercera palabra más común en el Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35923314-bc5d-454d-8f2e-1cca2ff06aea",
      "metadata": {
        "id": "35923314-bc5d-454d-8f2e-1cca2ff06aea"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 88584 # Parabras en nuestro diccionario\n",
        "\n",
        "MAXLEN = 250       # Longitud máxima de cada comentario\n",
        "BATCH_SIZE = 64    # Tamaño de Batch\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5f8996-5f14-429a-9fc4-e61646255ae6",
      "metadata": {
        "id": "4d5f8996-5f14-429a-9fc4-e61646255ae6"
      },
      "outputs": [],
      "source": [
        "print(len(train_data[0])) # Para conocer la longitud de un comentario\n",
        "print(train_data[0])      # Para visualizar un comentario"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "153da1d7-2f7f-473d-a8e8-a12c7aa46160",
      "metadata": {
        "id": "153da1d7-2f7f-473d-a8e8-a12c7aa46160"
      },
      "source": [
        "Los comentarios cargados en nuestro Dataset tienen diferentes longitudes. No podemos pasar elementos de diferente tamaño a nuestra Red Neuronal. Por tanto, debemos hacer que todos los comentarios tengan la misma longitud.\n",
        "1. Si el Comentario tiene más de 250 palabras, nos quedamos con las primeras 250.\n",
        "2. Si el Comentario tiene menos de 250 palabras, lo completamos con 0s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c6102fd-cddc-4ef2-8228-44a781a24783",
      "metadata": {
        "id": "6c6102fd-cddc-4ef2-8228-44a781a24783"
      },
      "outputs": [],
      "source": [
        "train_data = pad_sequences(train_data, MAXLEN)\n",
        "test_data = pad_sequences(test_data, MAXLEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "783c79ae-7090-4ac8-b975-39fae9c8852f",
      "metadata": {
        "id": "783c79ae-7090-4ac8-b975-39fae9c8852f"
      },
      "source": [
        "**Creación del Modelo:**\n",
        "\n",
        "Vamos a utilizar una capa de Word Embedding como primera capa del modelo y añadir una capa LSTM después, que entregará los datos resultantes a una capa Densa. Ésta última será la encargada de predecir el Sentimiento (Positivo, Negativo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4364928c-eb5e-4541-8184-2b7edf9649a1",
      "metadata": {
        "id": "4364928c-eb5e-4541-8184-2b7edf9649a1"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32), ## Creamos la capa de Word Embedding con vectores resultantes de 32 dimensiones por palabra\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fde07691-c6d6-40b8-b366-85a022dfb7cf",
      "metadata": {
        "id": "fde07691-c6d6-40b8-b366-85a022dfb7cf"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b9f9946-0a7a-4c82-a75e-ef1494f08202",
      "metadata": {
        "id": "1b9f9946-0a7a-4c82-a75e-ef1494f08202"
      },
      "source": [
        "**Entrenamiento del Modelo:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "179aa238-2757-4167-9bb1-f60b88ab74ec",
      "metadata": {
        "id": "179aa238-2757-4167-9bb1-f60b88ab74ec",
        "outputId": "010c39bd-3c16-4de8-93ce-2f4d376518d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 105s 145ms/step - loss: 0.4214 - acc: 0.8055 - val_loss: 0.2917 - val_acc: 0.8840\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 81s 129ms/step - loss: 0.2462 - acc: 0.9064 - val_loss: 0.2768 - val_acc: 0.8856\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 86s 137ms/step - loss: 0.1892 - acc: 0.9312 - val_loss: 0.2779 - val_acc: 0.8902\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.0912 - acc: 0.9711 - val_loss: 0.3467 - val_acc: 0.8884\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.0829 - acc: 0.9725 - val_loss: 0.3465 - val_acc: 0.8888\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 79s 126ms/step - loss: 0.0714 - acc: 0.9775 - val_loss: 0.3712 - val_acc: 0.8812\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68aff42b-2c93-48f1-be07-95be3a4eb1af",
      "metadata": {
        "id": "68aff42b-2c93-48f1-be07-95be3a4eb1af"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}