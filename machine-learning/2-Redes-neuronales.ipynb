{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59724343-33e6-4fe4-adf1-0e4a6172d683",
   "metadata": {},
   "source": [
    "### **Redes Neuronales** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42270e-44f2-4ef9-b1fe-f967c22c895e",
   "metadata": {},
   "source": [
    "Una Red Neuronal Profunda es una representación de datos en Capas. El término \"profunda\" hace referencia a la existencia de multiples Capas. Los datos de entrada se transforman en cada capa con el objetivo de aprender más sobre los mismos. El objetivo es predecir un resultado a partir de una serie de datos de entrada.\n",
    "\n",
    "Cada capa está compuesta por N neuronas conectadas con las capas previos y posteriores. Cada conexión entre neuronas se define por su **Peso** (ajustan la influencia de las entradas). Cada capa también puede tener un **Sesgo** (permiten ajustar la salida de una neurona independientemente de las entradas). Los sesgos permiten que la neurona tenga cierto nivel de activación incluso cuando todas las entradas son cero. Los sesgos son esenciales para que las redes neuronales puedan aprender patrones más complejos y realizar tareas específicas.\n",
    "\n",
    "Los datos comienzan en la **Capa de Entrada** y se transforman durante su paso por las **Capas Ocultas**, hasta llegar a la predicción en la **Capa de Salida**. El dato en cada neurona se define del siguiente modo (Suma con Pesos):\n",
    "\n",
    "$Y = (\\sum_{i = 0}^{n} w_{i}x_{i}) + b$ \n",
    "\n",
    "* w: peso de la conexión\n",
    "* x: valor de la neurona\n",
    "* b: sesgo de la capa (es una constante)\n",
    "* n: número de conexiones\n",
    "* Y: valor de salida de la neurona\n",
    "\n",
    "Para completar la ecuación, hay que incluir la **Función de Activación** F(x). Se aplica a la ecuación previa para añadir complejidad y dimensionalidad a la Red Neuronal. La ecuación resultante sería:\n",
    "\n",
    "$Y = F((\\sum_{i = 0}^{n} w_{i}x_{i}) + b)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663cb0f1-f912-428c-bd70-17bfc690e115",
   "metadata": {},
   "source": [
    "**Función de Activación:**\n",
    "\n",
    "La función de activación en una red neuronal es una función matemática aplicada a la salida de cada neurona, que determina si y en qué medida esa neurona debe activarse o no. En otras palabras, la función de activación introduce no linealidades en la red, permitiendo que la red aprenda patrones y relaciones más complejas en los datos. Algunas de las funciones de activación más comunes incluyen:\n",
    "\n",
    "* Función Sigmoide (Sigmoid): Esta función transforma sus entradas en el rango de 0 a 1, lo que la hace útil en problemas de clasificación binaria.\n",
    "\n",
    "<img src=\"..\\..\\Imágenes\\Función de Activación - Sigmoide.png\" width=\"300\"/>\n",
    "\n",
    "* Función Tangente Hiperbólica (Tanh): Similar a la función sigmoide, pero mapea las entradas al rango de -1 a 1, lo que puede ser útil para problemas de clasificación y regresión.\n",
    "\n",
    "<img src=\"..\\..\\Imágenes\\Función de Activación - Tangente Hiperbólica.png\" width=\"325\"/>\n",
    "\n",
    "* Rectified Linear Unit (ReLU): Esta función asigna cero a todas las entradas negativas y deja inalteradas las entradas positivas. Es ampliamente utilizada y ha demostrado ser efectiva en muchos casos.\n",
    "\n",
    "<img src=\"..\\..\\Imágenes\\Función de Activación - Rectified Linear Unit.png\" width=\"315\"/>\n",
    "\n",
    "* Leaky Rectified Linear Unit (Leaky ReLU): Es similar a ReLU, pero permite que las entradas negativas tengan un pequeño valor lineal en lugar de ser cero. Esto puede ayudar a mitigar algunos problemas asociados con ReLU.\n",
    "\n",
    "<img src=\"..\\..\\Imágenes\\Función de Activación - Leaky Rectified Linear Unit.png\" width=\"400\"/>\n",
    "\n",
    "* Unidad Lineal Rectificada (Linear Rectified Unit - ReLU): Similar a la función ReLU, pero sin truncar las entradas negativas a cero. Aunque puede causar problemas con el desvanecimiento del gradiente, se utiliza en ciertos contextos.a cero. Aunque puede causar problemas con el desvanecimiento del gradiente, se utiliza en ciertos contextos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70e802-e528-4261-ac9f-314d51e5888a",
   "metadata": {},
   "source": [
    "**Datos:**\n",
    "\n",
    "Los datos procesados por una Red Neuronal puede variar según el problema a solventar. Al contruir una Red Neuronal, definimos el tamaño y el tipo de dato que puede aceptar:\n",
    "\n",
    "* Vectores\n",
    "* Series Temporales o Secuencias\n",
    "* Imágenes\n",
    "* Vídeos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d76b33-b3b8-4932-81c6-b822f3825e9e",
   "metadata": {},
   "source": [
    "**Capas:**\n",
    "\n",
    "* Capa de Entrada: Recoge los datos de entrada.\n",
    "* Capa de Salida: Aporta los datos resultantes.\n",
    "* Capas Ocultas: Son las capas intermedias. No podemos observarlas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353fb249-7491-456a-9862-013660999f80",
   "metadata": {},
   "source": [
    "**Neuronas:**\n",
    "\n",
    "Cada neurona es responsable de Generar/Contener/Trasladar un valor numérico al siguiente nivel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac009f7-7a00-4d89-97d5-66ca452520a5",
   "metadata": {},
   "source": [
    "**Retropropagación:**\n",
    "\n",
    "Es el algoritmo utilizado para entrenar la red neuronal mediante la optimización de sus Pesos y Sesgos. Durante la retropropagación, se calculan los gradientes de la función de pérdida con respecto a los pesos y sesgos de la red.\n",
    "\n",
    "* **Función de Pérdida**(Loss Function): Es la manera en la que evaluamos la bondad del modelo. En los datos de entrenamiento, disponemos de las características (datos de entrada) y las etiquetas (resultados esperados). Por tanto, podemos comparar los datos resultantes del modelo con los resultados esperados. Basándonos en la diferencia entre ambos, podemos determinar si nuestra Red hace o no un buen trabajo. En base a la respuesta, decidiremos que cambios es necesario realizar a los Pesos y Sesgos. Hay varios tipos de Función de Coste, por ejemplo:\n",
    "\n",
    "    * Error Cuadrático Medio (Mean Squared Error)\n",
    "    * Error Absoluto Medio (Mean Absolute Error)\n",
    "    * Pérdida Bisagra (Hinge Loss)\n",
    "\n",
    "* **Pesos** (Weights): Representan la fuerza de las conexiones entre las neuronas. La retropropagación ajusta estos pesos para minimizar la diferencia entre las salidas predichas y las salidas reales.\n",
    "\n",
    "* **Sesgos** (Biases): Son parámetros adicionales que se suman a la salida de cada neurona. Los sesgos permiten a la red aprender patrones incluso cuando todas las entradas son cero. Durante la retropropagación, los gradientes con respecto a los sesgos también se calculan y se utilizan para ajustarlos de manera que la red mejore su rendimiento en la tarea específica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45d5621-abb3-491f-9b49-68580bada5d4",
   "metadata": {},
   "source": [
    "**[Optimizador](https://towardsdatascience.com/optimizers-for-training-neural-network-59450d71caf6):**\n",
    "\n",
    "Algoritmo de optimización utilizado para ajustar los pesos y sesgos de una red neuronal durante el proceso de entrenamiento. Los más comunes:\n",
    "\n",
    "* Descenso de Gradiente: Se calcula el gradiente de la función de pérdida con respecto a los pesos de la red. El gradiente indica la dirección en la cual la función de pérdida crece más rápidamente. El objetivo del Descenso del Gradiente es ajustar iterativamente los pesos en la dirección opuesta al gradiente, de manera que la función de pérdida se minimice.\n",
    "* Descenso del Gradiente Estocástico\n",
    "* Descenso del Gradiente por Mini-Batches\n",
    "* Momentum\n",
    "* Gradiente Acelerado de Nesterov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a061f-3989-4d54-aa0f-6d8c7993972c",
   "metadata": {},
   "source": [
    "## **[Creación de una Red Neuronal](https://www.tensorflow.org/tutorials/keras/classification):** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc0b0d3-6e93-4b25-be1a-1d15bac217ac",
   "metadata": {},
   "source": [
    "**Módulos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65828ace-3c20-45ef-97b6-c6ac169a648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "## Librerías de ayuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d92256-9674-49a5-878e-5670d394e5bd",
   "metadata": {},
   "source": [
    "**Dataset:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca0755a-d967-4d75-bee5-6c68bce77a8e",
   "metadata": {},
   "source": [
    "Vamos a utilizar un Dataset llamado MNIST Fashion (incluido en el módulo keras). Éste contiene 60.000 imágenes para entrenamiento y 10.000 imágenes para validación, divididas en 10 categorías. Por defecto, Keras realiza la descarga en la ubicación \"C:\\Users\\Jairo\\.keras\\datasets\\fashion-mnist\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324a9be-b06e-473d-970b-7c7abf95d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist                                         # Cargamos el Dataset Fashion Mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() # Separar entre Entrenamiento y Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df3951-37d8-4c44-ac83-aaeea04322af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "print(type(train_images))\n",
    "train_images[0, 23, 23]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b9269-955c-47cb-8aef-152197375a0e",
   "metadata": {},
   "source": [
    "Por tanto, disponemos de 60.000 imágenes para entrenar nuestra Red Neuronal. Cada imagen está compuesta por 28x28 pixels (784). Accedemos al pixel de la imagen 0 fila 23 y columna 23 y nos devuelve su color (valor numérico entre 0 -negor- y 255 -blanco-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a04e8-09c1-428f-a79c-7a1fda94dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels[:10]) # Devuelve 10 etiquetas (resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b094ab-95df-4c8c-b769-fa11333344a6",
   "metadata": {},
   "source": [
    "Las categorías de clasificación son:\n",
    "* 0 T-shirt/top | 1 Trouser | 2 Pullover | 3 Dress | 4 Coat | 5 Sandal\n",
    "* 6 Shirt       | 7 Sneaker | 8 Bag      | 9 Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c9db6-510a-4751-b1d6-b286bda0f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c65376-67ea-4d09-88b2-fb4f162e7597",
   "metadata": {},
   "source": [
    "Así se vería una de las imágenes con las que trabajamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec0807-5371-4d38-ba0a-89f2718f93ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()                # Cremos una figura\n",
    "plt.imshow(train_images[1]) # Indicamos la imagen a mostrar\n",
    "plt.colorbar()              # Incluimos la barra de color\n",
    "plt.grid(False)             # Indicamos que no queremos Cuadrícula\n",
    "plt.show()                  # Mostramos la imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb785b-fd01-4194-ac51-666e08440f1f",
   "metadata": {},
   "source": [
    "**Preprocesamiento de Datos:**\n",
    "\n",
    "El último paso antes de crear nuestro modelo, es preprocesar los datos. Es necesario aplicar algunas transformaciones a nuestros datos antes de pasárselos al modelo. En este caso, vamos a combertir el color de cada pixel de un valor entre 0 y 255 a un valor entre 0 y 1 (dividiendo cada valor por 255). Valores más pequeños facilitarán al modelo el tratamiento de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5766b8-df79-468c-a047-12874b555c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8f4f8-ac6d-4d26-aff1-7245609feca0",
   "metadata": {},
   "source": [
    "**Construcción del Modelo:**\n",
    "\n",
    "Vamos a utilizar un modelo secuencial de Keras con tres capas. Este modelo representa una Red Neuronal de Propagación Directa (Feed Forward Neural Network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb23b99-9272-45f8-998e-70ba21bc6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Capa de Entrada: Pasamos de una matriz 28x28 a un vector de 784 nueronas (cada pixel queda asociado a una neurona)\n",
    "    keras.layers.Dense(128, activation=\"relu\"),  # Capa Oculta: 128 neuronas (cada neurona de la capa anterior está conectada con todas las neuronas de esta capa)\n",
    "    keras.layers.Dense(10, activation=\"softmax\") # Capa de Salida: 10 neuronas (cada neurona de la capa anterior está conectada con todas las neuronas de esta capa)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476b2287-e308-4945-947d-b38212544064",
   "metadata": {},
   "source": [
    "**Compilar el Modelo:**\n",
    "\n",
    "Hay que definir la Función de Pérdida (Loss Function), el optimizador a utilizar y las métricas a las cuales queremos hacer el seguimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59709f64-cb2e-48d7-90cd-685d62209a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f4fc00-130f-474b-8d9b-8ddf202d9105",
   "metadata": {},
   "source": [
    "**Entrenamiento del Modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6148f75-488e-44cf-bfa4-b112d0626faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ba1b9-02a6-40c3-8ec9-de85cfa7dfcf",
   "metadata": {},
   "source": [
    "**Evaluación del Modelo:**\n",
    "\n",
    "El parámetro verbose indica (0 --> Oculto, 1 --> Barra de progreso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404c512-b2a5-4de8-88ef-4944611dd8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=1)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7d143-34e8-49ab-9471-89a67578298f",
   "metadata": {},
   "source": [
    "El dato de Exactitud (Accuracy) obtenido durante el proceso de entrenamiento es mayor que el obtenido durante el proceso de evaluación. Esto ocurre por lo que llamamos \"Overfitting\" (el modelo ha visto muchas veces los datos de entrada y los ha memorizado; por tanto, no funcionará tan bien con datos que se alejen de aquellos utilizados durante el proceso de entrenamiento). En este caso concreto, se obtendría un mejor resultado con 1 época que con 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ffd3d-1667-4745-bdba-f8ade4ce7025",
   "metadata": {},
   "source": [
    "**Hacer Predicciones:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df9f9c-9782-4f67-a669-046df9b51106",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "print(class_names[np.argmax(predictions[0])]) # La predicción indica que es la clase 9 (Ankle boot)\n",
    "plt.figure()                # Cremos una figura\n",
    "plt.imshow(test_images[0])  # Indicamos la imagen a mostrar\n",
    "plt.colorbar()              # Incluimos la barra de color\n",
    "plt.grid(False)             # Indicamos que no queremos Cuadrícula\n",
    "plt.show()                  # Mostramos la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219167e1-1539-4f77-80cf-3ab5f3b25b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
