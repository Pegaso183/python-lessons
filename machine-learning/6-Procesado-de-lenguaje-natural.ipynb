{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48379c1-d300-4f0f-aefc-bd504c3ae1f8",
   "metadata": {},
   "source": [
    "### **Procesado de Lenguaje Natural (NLP)** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878c928-9484-4dd1-a58b-97e5abd570b9",
   "metadata": {},
   "source": [
    "Su objetivo principal es permitir que las máquinas comprendan, interpreten y generen texto en un formato que sea comprensible para los seres humanos.\n",
    "\n",
    "El NLP se utiliza en una variedad de aplicaciones, como sistemas de traducción automática, asistentes virtuales, análisis de sentimientos, resumen automático de textos, y muchas otras áreas donde la interacción entre las máquinas y el lenguaje humano es esencial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd11585d-bde8-4e4d-b036-9be090d1d07c",
   "metadata": {},
   "source": [
    "**Word Embedding:**\n",
    "\n",
    "Las redes neuronales trabajan con elementos numéricos. Por tanto, debemos transformar las palabras en \"números\". Word Embedding es una técnica del procesamiento de lenguaje natural (NLP) que asigna palabras a vectores de números reales en un espacio continuo. Estos vectores representan de manera semántica el significado de las palabras. La idea principal es capturar similitudes y relaciones semánticas entre palabras basándose en su contexto de uso.\n",
    "\n",
    "**Redes Neuronales Recurrentes (RNN):**\n",
    "\n",
    "Redes neuronales diseñada para procesar secuencias de datos, donde la información tiene una estructura temporal o de orden. A diferencia de las redes neuronales tradicionales, las RNN tienen conexiones retroactivas, lo que les permite mantener y utilizar información previa en la tarea actual.\n",
    "\n",
    "La característica distintiva de las RNN es su capacidad para mantener una \"memoria\" interna de eventos anteriores en una secuencia. Cada unidad de la red, llamada neurona recurrente, toma una entrada junto con su estado anterior y produce una salida y un nuevo estado. Esto permite a las RNN aprender patrones en datos secuenciales y modelar dependencias a largo plazo.\n",
    "\n",
    "En una RNN, la salida de una neurona en un paso de tiempo se utiliza como entrada para la siguiente neurona en el siguiente paso de tiempo. Esto crea un bucle que permite a la red mantener información sobre eventos pasados y utilizarla para influir en las predicciones o representaciones en pasos futuros.\n",
    "\n",
    "Puede sufrir problemas de desvanecimiento o explosión del gradiente en entrenamientos a largo plazo.\n",
    "\n",
    "**Long Short-Term Memory (LSTM):**\n",
    "\n",
    "Son Redes Neuronales Recurrentes diseñada para abordar el problema de desvanecimiento del gradiente en RNN estándar. Las LSTM tienen unidades de memoria que permiten recordar información a lo largo del tiempo.\n",
    "\n",
    "La principal característica de las LSTM es su capacidad para retener y utilizar información a largo plazo en secuencias de datos. A diferencia de las RNN convencionales, las LSTM tienen unidades de memoria especializadas y utilizan puertas para controlar el flujo de información a través de la red. Estas puertas permiten a las LSTM decidir cuándo recordar, olvidar o utilizar la información en la memoria."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
