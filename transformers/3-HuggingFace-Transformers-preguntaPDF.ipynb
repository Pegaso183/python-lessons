{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **HugginFace - Transformers - Pregunta a tu PDF** ###\n",
        "\n",
        "Vamos a crear una aplicación que nos permita consultar a ChatGPT sobre la información que le proporcionemos en un documento PDF.\n",
        "\n",
        "## **Módulos:** ##"
      ],
      "metadata": {
        "id": "0YEvJAkHEYeI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4174LcPEU9f"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install langchain\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-gpu\n",
        "!pip install openai\n",
        "\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos trabajar con un PDF que tengamos en local o programar la descarga de un documento PDF disponible online.\n",
        "\n",
        "Si queremos descargar el manual de Python, podemos ejecutar la siguiente celda. En caso de querer trabajar con un PDF local, no ejecutar la siguiente celda."
      ],
      "metadata": {
        "id": "2o6LzRMaLFBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://aprendepython.es/_downloads/907b5202c1466977a8d6bd3a2641453f/aprendepython.pdf'\n",
        "doc_to_download = requests.get(URL)\n",
        "pdf_file = open('aprendepython.pdf','wb')\n",
        "pdf_file.write(doc_to_download.content)"
      ],
      "metadata": {
        "id": "9eME73JALYme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lectura de Fichero PDF** ##"
      ],
      "metadata": {
        "id": "ykC4tPp4NpzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "f93_5sX1NwrB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar fichero PDF\n",
        "pdf_file_obj = open('aprendepython.pdf', 'rb')\n",
        "pdf_reader = PdfReader(pdf_file_obj)\n",
        "\n",
        "text = ''\n",
        "for page in pdf_reader.pages:\n",
        "  text += page.extract_text()"
      ],
      "metadata": {
        "id": "VybWh6PIOEHo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Crear Chunks** ##\n",
        "\n",
        "Dado que no podemos pasarle a ChatGPT todo el texto de una vez, tenemos que dividirlo en trozos (Chunks) que sí podamos pasar como entrada de datos.\n",
        "\n",
        "Para hacer este trabajo, vamos a hacer uso de la librería *langchain*. La función RecursiveCharacterTextSplitter permite dividir un texto de entrada en trozos, considerando si es posible tomar párrafos completos, si no, frases, si no, palabras. Permite escoger la longitud de los trozos a crear y si queremos que haya \"overlap\" (parte del final de cada trozo, estará también como inicio del trozo siguiente. El objetivo es permitir una mayor comprensión del documento de entrada)."
      ],
      "metadata": {
        "id": "yUGSd4aQPRJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "buBDwhZePxMs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len\n",
        ")"
      ],
      "metadata": {
        "id": "lk-s8EK4RYjl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = text_splitter.split_text(text)"
      ],
      "metadata": {
        "id": "Il4SYvv8RtLY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(chunks))\n",
        "print(chunks[0])"
      ],
      "metadata": {
        "id": "G5mjpcJIR3Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Crear Embeddings:** ##\n",
        "\n",
        "Para pasarle los textos de entrada al modelo, primero debemos convertirlos en valores numéricos. Para crear los Embeddings vamos a utilizar el modelo \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\" (modelo pre-entrenado para detección de paráfrasis multilingüe).\n",
        "\n",
        "**Características principales:**\n",
        "\n",
        "* Multilingüe: Funciona con más de 50 idiomas, por lo que puede comparar textos en diferentes lenguas.\n",
        "* Detección de paráfrasis: Identifica si dos oraciones dicen lo mismo con palabras diferentes, incluso dentro de idiomas distintos.\n",
        "* Aprendizaje MiniLM-L12: Se basa en la arquitectura Transformer, específicamente utilizando la variante MiniLM-L12, que es eficiente y flexible.\n",
        "* Vectorización semántica: Representa oraciones como vectores de 384 dimensiones, permitiendo comparar el significado de manera numérica.\n",
        "\n",
        "\n",
        "**Aplicaciones:**\n",
        "\n",
        "* Búsqueda semántica: Encontrar documentos relevantes en grandes colecciones de texto, a pesar de las diferencias de redacción.\n",
        "* Eliminación de duplicados: Identificar y eliminar textos redundantes en diferentes idiomas.\n",
        "* Minería de texto: Analizar grandes conjuntos de datos textuales identificando relaciones semánticas entre oraciones.\n",
        "* Chatbots multilingües: Desarrollar chatbots capaces de entender y responder en múltiples idiomas."
      ],
      "metadata": {
        "id": "x231YsGK7ueq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dos tamaños\n",
        "'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2' #  471M\n",
        "'sentence-transformers/paraphrase-multilingual-mpnet-base-v2' # 1.11G"
      ],
      "metadata": {
        "id": "A72riXOr_2sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "jdpGMmAZB_Sp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")"
      ],
      "metadata": {
        "id": "sh3lJ0BpCH2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez cargado el modelo, podemos usarlo para crear los embeddings de nuestros chunks."
      ],
      "metadata": {
        "id": "ETJc7HHGDzsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "8FEr8R7TECO-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knowledge_base = FAISS.from_texts(chunks, embeddings)"
      ],
      "metadata": {
        "id": "lRFGnlt9EJBz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos creado una base de datos local que contiene el conocimiento de nuestro documento PDF. Ahora, le podemos pedir a dicha BD que nos devuelva los N chunks que más relación semántica tengan con la consulta que queremos hacer al documento."
      ],
      "metadata": {
        "id": "E0lOCrNrEfq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = '¿Qué es VSCode?'\n",
        "docs = knowledge_base.similarity_search(pregunta, 3)"
      ],
      "metadata": {
        "id": "zbUfNnOPE2l_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "5Rgg6y9_IiqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preguntar al documento PDF** ##\n",
        "\n",
        "Vamos a lanzar una consulta al documento PDF haciendo uso de ChatGPT. Para ello, necesaritamos contar con la [clave API de OpenIA](https://platform.openai.com/api-keys)."
      ],
      "metadata": {
        "id": "2Fl0oC24oCwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Añadimos la API key como variable de entorno (la tomamos de los Secretos de GoogleColab)\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OpenIA_Key')"
      ],
      "metadata": {
        "id": "FdA4qEw9IkAq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "Wo4IPz3lqp_B"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name = 'gpt-3.5-turbo')\n",
        "chain = load_qa_chain(llm, chain_type='stuff')"
      ],
      "metadata": {
        "id": "RVpVwYq0q_s0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = '¿Qué es VSCode?'\n",
        "docs = knowledge_base.similarity_search(pregunta, 3)\n",
        "respuesta = chain.run(input_documents=docs, question=pregunta)\n",
        "print(f\"Respuesta ChatGPT: {respuesta}\")"
      ],
      "metadata": {
        "id": "DzZWHgAgsvfi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}